
ucsv=function(y,display=FALSE){
  
  T = length(y);
  nloop = 4000;
  burnin = 1000;
  ## prior
  Vtau = 0.12; Vh = 0.12;
  atau = 10; ltau = 0.04*9;
  ah = 10; lh = 0.03*9;
  ## initialize the Markov chain
  omega2tau = ltau/(atau-1);
  omega2h = lh/(ah-1);
  h = as.numeric(log(var(y)*.8)) * matrix(rep(1,T));
  ####<Making a sparse matrix>####
  Sp=diag(T);                    #
  d=matrix(rep(0,T),1);          #
  sparse=rbind(d,Sp);            #
  sparse<-sparse[-(T+1),]        #
  ################################
  H = diag(T) - sparse;
  ## initialize for storage
  store_omega2tau = matrix(rep(0,(nloop-burnin)),,1);
  store_omega2h = matrix(rep(0,(nloop-burnin)),,1);
  store_tau = matrix(rep(0,(nloop-burnin)*T),,T);
  store_h = matrix(rep(0,(nloop-burnin)*T),,T);
  ## compute a few things
  newatau = (T-1)/2 + atau;
  newah = (T-1)/2 + ah;
  for (loop in 1:nloop){
    ## sample tau
    invOmegatau = diag(T)*c(1/Vtau, 1/omega2tau*rep(1,T-1));
    invSigy = diag(T)*c(exp(-h));
    Ktau = t(H) %*% invOmegatau %*% H + invSigy;
    Ctau = t(chol(Ktau));
    tauhat = solve(Ktau,(invSigy %*% y));
    tau = tauhat + solve(t(Ctau), matrix(rnorm(T),,1));
    ## sample h
    ystar = log((y-tau)^2 + .0001 );  
    result = SVRW(ystar,h,omega2h,Vh);
    h = result[[1]];
    ## sample omega2tau
    newltau = ltau + sum((tau[2:nrow(tau)]-tau[1:(nrow(tau)-1)])^2)/2;
    omega2tau = 1/gamrand(newatau, newltau);
    ## sample omega2h
    newlh = lh + sum((h[2:nrow(h)]-h[1:(nrow(h)-1)])^2)/2;
    omega2h = 1/gamrand(newah, newlh);
    if (loop>burnin){
      i = loop-burnin;
      store_tau[i,] = t(tau);
      store_h[i,] = t(h);
      store_omega2tau[i,] = omega2tau;
      store_omega2h[i,] = omega2h; 
    }
  }
  tauhat = matrix(rowMeans(t(store_tau)));
  hhat = matrix(colMeans(store_h));
  
  
  if(display==TRUE){
    plot(y,type="l")
    lines(tauhat,col="blue")
  }
  
  return(list("tauhat"=tauhat,"hhat"=hhat,"store_tau"=store_tau,"store_h"=store_h))
}


ucsv.rw=function(Y,npred,h=1:3){
  
  z=npred+length(h)-1
  save.p=rep(NA,z)
  # for(i in z:1){
  
  myfunction <- function(i) {
    library(HDeconometrics)
    
    res_temp <- list()
    
    res_temp$m=ucsv(Y[(z-i+1):(length(Y)-i)],FALSE)
    # save.p[z-i+1]=tail(m$tauhat,1)
    # cat(z-i+1,"\n")
    return(res_temp)
    
  }
  
  no_cores <- detectCores(logical = TRUE)  # returns the number of available hardware threads, and if it is FALSE, returns the number of physical cores
  
  cl <- makeCluster(no_cores-1)
  clusterSetRNGStream(cl = cl, iseed = 123)
  
  clusterExport(cl,c('myfunction',
                     'npred',
                     'z',
                     'Y',
                     'ucsv',
                     'SVRW',
                     'gamrand'  ),
                envir = environment()
  )
  
  #registerDoParallel(cl)
  
  
  # start.time <- Sys.time()
  
  res_list <- parallel::parLapply(cl = cl, z:1, fun = myfunction)
  
  stopCluster(cl)
  
  # end.time <- Sys.time()
  # time.taken <- end.time - start.time
  # time.taken
  
  for (i in z:1){
    save.p[z-i+1]=tail(res_list[[i]]$m$tauhat,1)
    
    # save.pred[(nprev+1-i),]=res_list[[i]]$save.pred
  }
  
  
  pr=matrix(NA,npred,length(h))
  for(i in 1:length(h)){
    pr[,i]=tail(save.p,npred)
    save.p=save.p[-length(save.p)]
  }
  return(pr)
}

# SVRW.r
SVRW<-function(ystar,h,omega2h,Vh){
  T = length(h);
  ## parameters for the Gaussian mixture
  pi = c(0.0073, .10556, .00002, .04395, .34001, .24566, .2575);
  mui = c(-10.12999, -3.97281, -8.56686, 2.77786, .61942, 1.79518,-1.08819) - 1.2704; 
  sig2i = c(5.79596, 2.61369, 5.17950, .16735, .64009, .34023, 1.26261);
  sigi = sqrt(sig2i);
  ## sample S from a 7-point distrete distribution
  temprand = matrix(runif(T));
  q = matrix(rep(pi,each=T),T) * dnorm(matrix(rep(ystar,each=7),byrow=TRUE,,7),matrix(rep(h,each=7),byrow=TRUE,,7)
                                       +matrix(rep(mui,each=T),T),matrix(rep(sigi,each=T),T));
  q = q/matrix(rep(rowSums(q),each=7),byrow=TRUE,,7);
  S = matrix(7 - rowSums(matrix(rep(temprand,each=7),byrow=TRUE,,7)<t(apply(q,1,cumsum)))+1);
  ## sample h
  ####<Making a sparse matrix>####
  Sp=diag(T);                    #
  d=matrix(rep(0,T),1);          #
  sparse=rbind(d,Sp);            #
  sparse<-sparse[-(T+1),]        #
  ################################
  H = diag(T) - sparse;
  invOmegah = diag(T)*c(1/Vh, 1/omega2h*rep(1,T-1));
  d = matrix(mui[S]); invSigystar = diag(T)*c(1/sig2i[S]);
  Kh = t(H) %*% invOmegah %*% H + invSigystar;
  Ch = t(chol(Kh));
  hhat = solve(Kh,(invSigystar %*% (ystar-d)));
  h = hhat + solve(t(Ch),matrix(rnorm(T)));
  result = list(h,S);
  return (result)
}

gamrand<-function(alpha,lambda){
  if (alpha>1)
  {
    d=alpha-1/3;
    c=1/sqrt(9*d); 
    flag=1;
    while (flag){
      Z=rnorm(1);
      if (Z>(-1/c)){
        V=(1+c*Z)^3;
        U=runif(1);
        flag=log(U)>(0.5*Z^2+d-d*V+d*log(V));  
      }
    }
    x=d*V/lambda;
  }
  else{
    x=gamrand(alpha+1,lambda);
    x=x*runif(1)^(1/alpha);
  }
}

source("UK/first-sample/functions/rep_Eoghan_newPCAoldstart/func-ucsv-par.R")
library(HDeconometrics)
library(parallel)
load("UK/first-sample/rawdata.rda")

Y=dados[,1:2]

nprev=132

## == presente == ##
ucsv.cpi=ucsv.rw(100*Y[,1],nprev,1:12)/100
ucsv.pce=ucsv.rw(100*Y[,2],nprev,1:12)/100

write.table(ucsv.cpi,"UK/forecasts/rep_passado2000_fixed_oldstart/ucsv-cpi.csv",sep=";",row.names = FALSE, col.names = FALSE)
write.table(ucsv.pce,"UK/forecasts/rep_passado2000_fixed_oldstart/ucsv-pce.csv",sep=";",row.names = FALSE, col.names = FALSE)





write.table(ucsv.cpi,"UK/forecasts/rep_passado2000_fixed_oldstart/ucsv-cpi.csv",sep=";",row.names = FALSE, col.names = FALSE)
write.table(ucsv.pce,"UK/forecasts/rep_passado2000_fixed_oldstart/ucsv-pce.csv",sep=";",row.names = FALSE, col.names = FALSE)






real=tail(Y,nprev)




ucsv1p <- list() 
ucsv2p <- list() 
ucsv3p <- list() 
ucsv4p <- list() 
ucsv5p <- list() 
ucsv6p <- list() 
ucsv7p <- list() 
ucsv8p <- list() 
ucsv9p <- list() 
ucsv10p <- list() 
ucsv11p <- list() 
ucsv12p <- list()



ucsv1c <- list() 
ucsv2c <- list() 
ucsv3c <- list() 
ucsv4c <- list() 
ucsv5c <- list() 
ucsv6c <- list() 
ucsv7c <- list() 
ucsv8c <- list() 
ucsv9c <- list() 
ucsv10c <- list() 
ucsv11c <- list() 
ucsv12c <- list()

#for cpi
for(i in 1:12){
  
  temp_pred <- ucsv.cpi[,i]
  temp_real <- real[,1]
  tempY <- dados[,1]
  
  # temp_predint <- aux_predints[[i]][,,1]
  
  rmse=sqrt(mean((temp_real-temp_pred)^2))
  mae=mean(abs(temp_real-temp_pred))
  
  #median absolute deviation from the median in paper, but not in code
  mad = median(abs(temp_real-temp_pred - median(temp_real-temp_pred)))
  
  #mean absolute deviation from  he mean
  mean_ad = mean(abs(temp_real-temp_pred - mean(temp_real-temp_pred)))
  
  
  #mean relative absolute error (relative to random walk)
  #last 132 lagged one month values are
  #real[(nrow(dados)-nprev):(nrow(dados)-1)]
  mrae = mean(abs( (temp_real-temp_pred)/
                     (temp_real-tempY[(nrow(dados)-nprev):(nrow(dados)-1)]  )     ))
  
  #mean absolute scaled error
  #equivalent to mae of method divided by nae of naive forecast
  #first calculate the denomiator
  #mean of vector of length nprev-1
  tempdenom = mean( abs(tail(temp_real,nprev-1) - tempY[(nrow(dados)-nprev+1):(nrow(dados)-1)]  ) )
  #then the overall measure is
  mase=mae/tempdenom
  
  #mean absolute percentage error
  mape = (100/nprev)*mean(abs((temp_real-temp_pred)/temp_real))
  
  #normalized rmse
  nrmse = rmse/(max(temp_real)-min(temp_real))
  
  #rmse relative to random walk
  
  #rmse of naive rw forecast
  rwrmse=sqrt(mean((temp_real-tempY[(nrow(dados)-nprev):(nrow(dados)-1)])^2))
  
  rmse_rel_rw = rmse/rwrmse
  
  
  errors=c("rmse"=rmse,
           "mae"=mae,
           "mad"=mad,
           "mean_ad"=mean_ad,
           "mrae"=mrae,
           "mase"=mase,
           "mape"=mape,
           "nrmse"=nrmse,
           "rmse_rel_rw"=rmse_rel_rw)
  
  #mean prediction interval coverage
  # predint_cov = mean( 1*((temp_predint[,1] < temp_real)  & (temp_real < temp_predint[,2])   ))
  
  #mean prediction interval width
  # predint_width = mean(temp_predint[,2] - temp_predint[,1])
  
  
  Object = get(paste0("ucsv", i,"c"))
  Object$pred <- temp_pred
  Object$errors <- errors
  # Object$save.pred_intervals <- temp_predint
  # Object$predint_cov <- predint_cov
  # Object$predint_width <- predint_width
  
  assign(paste0("ucsv_", i,"c"), Object)
  
  
}





#for pce
for(i in 1:12){
  
  temp_pred <- ucsv.pce[,i]
  temp_real <- real[,2]
  tempY <- dados[,2]
  
  # temp_predint <- aux_predints[[i]][,,2]
  
  rmse=sqrt(mean((temp_real-temp_pred)^2))
  mae=mean(abs(temp_real-temp_pred))
  
  #median absolute deviation from the median in paper, but not in code
  mad = median(abs(temp_real-temp_pred - median(temp_real-temp_pred)))
  
  #mean absolute deviation from  he mean
  mean_ad = mean(abs(temp_real-temp_pred - mean(temp_real-temp_pred)))
  
  
  #mean relative absolute error (relative to random walk)
  #last 132 lagged one month values are
  #real[(nrow(dados)-nprev):(nrow(dados)-1)]
  mrae = mean(abs( (temp_real-temp_pred)/
                     (temp_real-tempY[(nrow(dados)-nprev):(nrow(dados)-1)]  )     ))
  
  #mean absolute scaled error
  #equivalent to mae of method divided by nae of naive forecast
  #first calculate the denomiator
  #mean of vector of length nprev-1
  tempdenom = mean( abs(tail(temp_real,nprev-1) - tempY[(nrow(dados)-nprev+1):(nrow(dados)-1)]  ) )
  #then the overall measure is
  mase=mae/tempdenom
  
  #mean absolute percentage error
  mape = (100/nprev)*mean(abs((temp_real-temp_pred)/temp_real))
  
  #normalized rmse
  nrmse = rmse/(max(temp_real)-min(temp_real))
  
  #rmse relative to random walk
  
  #rmse of naive rw forecast
  rwrmse=sqrt(mean((temp_real-tempY[(nrow(dados)-nprev):(nrow(dados)-1)])^2))
  
  rmse_rel_rw = rmse/rwrmse
  
  
  errors=c("rmse"=rmse,
           "mae"=mae,
           "mad"=mad,
           "mean_ad"=mean_ad,
           "mrae"=mrae,
           "mase"=mase,
           "mape"=mape,
           "nrmse"=nrmse,
           "rmse_rel_rw"=rmse_rel_rw)
  
  #mean prediction interval coverage
  # predint_cov = mean( 1*((temp_predint[,1] < temp_real)  & (temp_real < temp_predint[,2])   ))
  
  #mean prediction interval width
  # predint_width = mean(temp_predint[,2] - temp_predint[,1])
  
  
  Object = get(paste0("ucsv", i,"p"))
  Object$pred <- temp_pred
  Object$errors <- errors
  # Object$save.pred_intervals <- temp_predint
  # Object$predint_cov <- predint_cov
  # Object$predint_width <- predint_width
  
  assign(paste0("ucsv_", i,"p"), Object)
  
  
}






save(ucsv_1c,ucsv_2c,ucsv_3c,ucsv_4c,
     ucsv_5c,ucsv_6c,ucsv_7c,ucsv_8c,
     ucsv_9c,ucsv_10c,ucsv_11c,ucsv_12c ,
     file = "UK/forecasts/rep_passado2000_fixed_oldstart/ucsv-all-cpi.Rdata")


ucsv_cpi_list <- list(ucsv_1c,ucsv_2c,ucsv_3c,ucsv_4c,
                      ucsv_5c,ucsv_6c,ucsv_7c,ucsv_8c,
                      ucsv_9c,ucsv_10c,ucsv_11c,ucsv_12c)

save(ucsv_cpi_list ,file =  "UK/forecasts/rep_passado2000_fixed_oldstart/ucsv-list-cpi.Rdata")


ucsv_pce_list <- list(ucsv_1p,ucsv_2p,ucsv_3p,ucsv_4p,
                      ucsv_5p,ucsv_6p,ucsv_7p,ucsv_8p,
                      ucsv_9p,ucsv_10p,ucsv_11p,ucsv_12p)

save(ucsv_pce_list , file = "UK/forecasts/rep_passado2000_fixed_oldstart/ucsv-list-pce.Rdata")











